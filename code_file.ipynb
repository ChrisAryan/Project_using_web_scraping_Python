{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc970287",
   "metadata": {},
   "source": [
    "## Done by Aryan Parashar (Internshala id=aryan.20b0121082@abes.ac.in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437210d6",
   "metadata": {},
   "source": [
    "# Importing input file and checking it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8730d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 114 entries, 0 to 113\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   URL_ID  114 non-null    int64 \n",
      " 1   URL     114 non-null    object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 1.9+ KB\n",
      "https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\n",
      "https://insights.blackcoffer.com/what-if-the-creation-is-taking-over-the-creator/\n",
      "https://insights.blackcoffer.com/what-jobs-will-robots-take-from-humans-in-the-future/\n",
      "https://insights.blackcoffer.com/will-machine-replace-the-human-in-the-future-of-work/\n",
      "https://insights.blackcoffer.com/will-ai-replace-us-or-work-with-us/\n",
      "https://insights.blackcoffer.com/man-and-machines-together-machines-are-more-diligent-than-humans-blackcoffe/\n",
      "https://insights.blackcoffer.com/in-future-or-in-upcoming-years-humans-and-machines-are-going-to-work-together-in-every-field-of-work/\n",
      "https://insights.blackcoffer.com/how-neural-networks-can-be-applied-in-various-areas-in-the-future/\n",
      "https://insights.blackcoffer.com/how-machine-learning-will-affect-your-business/\n",
      "https://insights.blackcoffer.com/deep-learning-impact-on-areas-of-e-learning/\n",
      "https://insights.blackcoffer.com/how-to-protect-future-data-and-its-privacy-blackcoffer/\n",
      "https://insights.blackcoffer.com/how-machines-ai-automations-and-robo-human-are-effective-in-finance-and-banking/\n",
      "https://insights.blackcoffer.com/ai-human-robotics-machine-future-planet-blackcoffer-thinking-jobs-workplace/\n",
      "https://insights.blackcoffer.com/how-ai-will-change-the-world-blackcoffer/\n",
      "https://insights.blackcoffer.com/future-of-work-how-ai-has-entered-the-workplace/\n",
      "https://insights.blackcoffer.com/ai-tool-alexa-google-assistant-finance-banking-tool-future/\n",
      "https://insights.blackcoffer.com/ai-healthcare-revolution-ml-technology-algorithm-google-analytics-industrialrevolution/\n",
      "https://insights.blackcoffer.com/all-you-need-to-know-about-online-marketing/\n",
      "https://insights.blackcoffer.com/evolution-of-advertising-industry/\n",
      "https://insights.blackcoffer.com/how-data-analytics-can-help-your-business-respond-to-the-impact-of-covid-19/\n",
      "https://insights.blackcoffer.com/covid-19-environmental-impact-for-the-future/\n",
      "https://insights.blackcoffer.com/environmental-impact-of-the-covid-19-pandemic-lesson-for-the-future/\n",
      "https://insights.blackcoffer.com/how-data-analytics-and-ai-are-used-to-halt-the-covid-19-pandemic/\n",
      "https://insights.blackcoffer.com/difference-between-artificial-intelligence-machine-learning-statistics-and-data-mining/\n",
      "https://insights.blackcoffer.com/how-python-became-the-first-choice-for-data-science/\n",
      "https://insights.blackcoffer.com/how-google-fit-measure-heart-and-respiratory-rates-using-a-phone/\n",
      "https://insights.blackcoffer.com/what-is-the-future-of-mobile-apps/\n",
      "https://insights.blackcoffer.com/impact-of-ai-in-health-and-medicine/\n",
      "https://insights.blackcoffer.com/telemedicine-what-patients-like-and-dislike-about-it/\n",
      "https://insights.blackcoffer.com/how-we-forecast-future-technologies/\n",
      "https://insights.blackcoffer.com/can-robots-tackle-late-life-loneliness/\n",
      "https://insights.blackcoffer.com/embedding-care-robots-into-society-socio-technical-considerations/\n",
      "https://insights.blackcoffer.com/management-challenges-for-future-digitalization-of-healthcare-services/\n",
      "https://insights.blackcoffer.com/are-we-any-closer-to-preventing-a-nuclear-holocaust/\n",
      "https://insights.blackcoffer.com/will-technology-eliminate-the-need-for-animal-testing-in-drug-development/\n",
      "https://insights.blackcoffer.com/will-we-ever-understand-the-nature-of-consciousness/\n",
      "https://insights.blackcoffer.com/will-we-ever-colonize-outer-space/\n",
      "https://insights.blackcoffer.com/what-is-the-chance-homo-sapiens-will-survive-for-the-next-500-years/\n",
      "https://insights.blackcoffer.com/why-does-your-business-need-a-chatbot/\n",
      "https://insights.blackcoffer.com/how-you-lead-a-project-or-a-team-without-any-technical-expertise/\n",
      "https://insights.blackcoffer.com/can-you-be-great-leader-without-technical-expertise/\n",
      "https://insights.blackcoffer.com/how-does-artificial-intelligence-affect-the-environment/\n",
      "https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes-2/\n",
      "https://insights.blackcoffer.com/is-perfection-the-greatest-enemy-of-productivity/\n",
      "https://insights.blackcoffer.com/global-financial-crisis-2008-causes-effects-and-its-solution/\n",
      "https://insights.blackcoffer.com/gender-diversity-and-equality-in-the-tech-industry/\n",
      "https://insights.blackcoffer.com/how-to-overcome-your-fear-of-making-mistakes/\n",
      "https://insights.blackcoffer.com/how-small-business-can-survive-the-coronavirus-crisis/\n",
      "https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors-and-food-stalls/\n",
      "https://insights.blackcoffer.com/impacts-of-covid-19-on-vegetable-vendors/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-tourism-aviation-industries/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-sports-events-around-the-world/\n",
      "https://insights.blackcoffer.com/changing-landscape-and-emerging-trends-in-the-indian-it-ites-industry/\n",
      "https://insights.blackcoffer.com/online-gaming-adolescent-online-gaming-effects-demotivated-depression-musculoskeletal-and-psychosomatic-symptoms/\n",
      "https://insights.blackcoffer.com/human-rights-outlook/\n",
      "https://insights.blackcoffer.com/how-voice-search-makes-your-business-a-successful-business/\n",
      "https://insights.blackcoffer.com/how-the-covid-19-crisis-is-redefining-jobs-and-services/\n",
      "https://insights.blackcoffer.com/how-to-increase-social-media-engagement-for-marketers/\n",
      "https://insights.blackcoffer.com/impacts-of-covid-19-on-streets-sides-food-stalls/\n",
      "https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets-2/\n",
      "https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-5/\n",
      "https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-4/\n",
      "https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-2/\n",
      "https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work-3/\n",
      "https://insights.blackcoffer.com/travel-and-tourism-outlook/\n",
      "https://insights.blackcoffer.com/gaming-disorder-and-effects-of-gaming-on-health/\n",
      "https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation/\n",
      "https://insights.blackcoffer.com/what-is-the-repercussion-of-the-environment-due-to-the-covid-19-pandemic-situation-2/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-pandemic-on-office-space-and-co-working-industries/\n",
      "https://insights.blackcoffer.com/contribution-of-handicrafts-visual-arts-literature-in-the-indian-economy/\n",
      "https://insights.blackcoffer.com/how-covid-19-is-impacting-payment-preferences/\n",
      "https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-2/\n",
      "https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis/\n",
      "https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding/\n",
      "https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-2/\n",
      "https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-3/\n",
      "https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-3/\n",
      "https://insights.blackcoffer.com/estimating-the-impact-of-covid-19-on-the-world-of-work/\n",
      "https://insights.blackcoffer.com/covid-19-how-have-countries-been-responding-2/\n",
      "https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work-4/\n",
      "https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-2/\n",
      "https://insights.blackcoffer.com/lessons-from-the-past-some-key-learnings-relevant-to-the-coronavirus-crisis-3/\n",
      "https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry-4/\n",
      "https://insights.blackcoffer.com/why-scams-like-nirav-modi-happen-with-indian-banks/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy-2/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-on-the-global-economy-2/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-3/\n",
      "https://insights.blackcoffer.com/should-celebrities-be-allowed-to-join-politics/\n",
      "https://insights.blackcoffer.com/how-prepared-is-india-to-tackle-a-possible-covid-19-outbreak/\n",
      "https://insights.blackcoffer.com/how-will-covid-19-affect-the-world-of-work/\n",
      "https://insights.blackcoffer.com/controversy-as-a-marketing-strategy/\n",
      "https://insights.blackcoffer.com/coronavirus-impact-on-the-hospitality-industry/\n",
      "https://insights.blackcoffer.com/coronavirus-impact-on-energy-markets/\n",
      "https://insights.blackcoffer.com/what-are-the-key-policies-that-will-mitigate-the-impacts-of-covid-19-on-the-world-of-work/\n",
      "https://insights.blackcoffer.com/marketing-drives-results-with-a-focus-on-problems/\n",
      "https://insights.blackcoffer.com/continued-demand-for-sustainability/\n",
      "https://insights.blackcoffer.com/coronavirus-disease-covid-19-effect-the-impact-and-role-of-mass-media-during-the-pandemic/\n",
      "https://insights.blackcoffer.com/should-people-wear-fabric-gloves-seeking-evidence-regarding-the-differential-transfer-of-covid-19-or-coronaviruses-generally-between-surfaces/\n",
      "https://insights.blackcoffer.com/why-is-there-a-severe-immunological-and-inflammatory-explosion-in-those-affected-by-sarms-covid-19/\n",
      "https://insights.blackcoffer.com/what-do-you-think-is-the-lesson-or-lessons-to-be-learned-with-covid-19/\n",
      "https://insights.blackcoffer.com/coronavirus-the-unexpected-challenge-for-the-european-union/\n",
      "https://insights.blackcoffer.com/industrial-revolution-4-0-pros-and-cons/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-indian-economy-2/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19coronavirus-on-the-indian-economy/\n",
      "https://insights.blackcoffer.com/impact-of-covid-19-coronavirus-on-the-global-economy/\n",
      "https://insights.blackcoffer.com/ensuring-growth-through-insurance-technology/\n",
      "https://insights.blackcoffer.com/blockchain-in-fintech/\n",
      "https://insights.blackcoffer.com/blockchain-for-payments/\n",
      "https://insights.blackcoffer.com/the-future-of-investing/\n",
      "https://insights.blackcoffer.com/big-data-analytics-in-healthcare/\n",
      "https://insights.blackcoffer.com/business-analytics-in-the-healthcare-industry/\n",
      "https://insights.blackcoffer.com/challenges-and-opportunities-of-big-data-in-healthcare/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "input_file=pd.read_excel(\"Input.xlsx\",sheet_name='Sheet1')\n",
    "input_file.info()\n",
    "for url in input_file[\"URL\"]:\n",
    "    print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e9c19",
   "metadata": {},
   "source": [
    "# Making a list of all the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c58ad480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ernst',\n",
       " 'young',\n",
       " 'deloitte',\n",
       " 'touche',\n",
       " 'kpmg',\n",
       " 'pricewaterhousecoopers',\n",
       " 'pricewaterhouse',\n",
       " 'coopers',\n",
       " 'afghani  | afghanistan ',\n",
       " 'ariary | madagascar ',\n",
       " 'baht | thailand ',\n",
       " 'balboa | panama ',\n",
       " 'birr | ethiopia ',\n",
       " 'bolivar | venezuela ',\n",
       " 'boliviano  | bolivia ',\n",
       " 'cedi | ghana ',\n",
       " 'colon  | costa rica ',\n",
       " 'córdoba  | nicaragua ',\n",
       " 'dalasi | gambia ',\n",
       " 'denar | macedonia (former yug. rep.) ',\n",
       " 'dinar | algeria ',\n",
       " 'dirham  | morocco ',\n",
       " 'dobra | são tom and príncipe ',\n",
       " 'dong | vietnam ',\n",
       " 'dram | armenia ',\n",
       " 'escudo  | cape verde ',\n",
       " 'euro  | belgium ',\n",
       " 'florin | aruba ',\n",
       " 'forint | hungary ',\n",
       " 'gourde | haiti ',\n",
       " 'guarani | paraguay ',\n",
       " 'gulden | netherlands antilles ',\n",
       " 'hryvnia  | ukraine ',\n",
       " 'kina | papua new guinea ',\n",
       " 'kip | laos ',\n",
       " 'konvertibilna marka  | bosnia-herzegovina ',\n",
       " 'koruna  | czech republic ',\n",
       " 'krona | sweden ',\n",
       " 'krone | denmark ',\n",
       " 'kroon | estonia ',\n",
       " 'kuna | croatia ',\n",
       " 'kwacha | zambia ',\n",
       " 'kwanza | angola ',\n",
       " 'kyat | myanmar ',\n",
       " 'lari | georgia ',\n",
       " 'lats | latvia ',\n",
       " 'lek | albania ',\n",
       " 'lempira | honduras ',\n",
       " 'leone | sierra leone ',\n",
       " 'leu | romania ',\n",
       " 'lev | bulgaria ',\n",
       " 'lilangeni  | swaziland ',\n",
       " 'lira | lebanon ',\n",
       " 'litas | lithuania ',\n",
       " 'loti | lesotho ',\n",
       " 'manat | azerbaijan ',\n",
       " 'metical | mozambique ',\n",
       " 'naira | nigeria ',\n",
       " 'nakfa | eritrea ',\n",
       " 'new lira | turkey ',\n",
       " 'new sheqel  | israel ',\n",
       " 'ngultrum  | bhutan ',\n",
       " 'nuevo sol | peru ',\n",
       " 'ouguiya  | mauritania ',\n",
       " 'pataca | macau ',\n",
       " 'peso  | mexico ',\n",
       " 'pound  | egypt ',\n",
       " 'pula  | botswana ',\n",
       " 'quetzal | guatemala ',\n",
       " 'rand | south africa ',\n",
       " 'real  | brazil ',\n",
       " 'renminbi  | china ',\n",
       " 'rial | iran ',\n",
       " 'riel | cambodia ',\n",
       " 'ringgit | malaysia ',\n",
       " 'riyal | saudi arabia ',\n",
       " 'ruble | russia ',\n",
       " 'rufiyaa | maldives ',\n",
       " 'rupee  | india ',\n",
       " 'rupee  | pakistan ',\n",
       " 'rupiah  | indonesia ',\n",
       " 'shilling  | uganda ',\n",
       " 'som | uzbekistan ',\n",
       " 'somoni  | tajikistan ',\n",
       " 'special drawing rights  | international monetary fund ',\n",
       " 'taka | bangladesh ',\n",
       " 'tala | western samoa ',\n",
       " 'tenge | kazakhstan ',\n",
       " 'tugrik  | mongolia ',\n",
       " 'vatu | vanuatu ',\n",
       " 'won  | korea, south ',\n",
       " 'yen | japan ',\n",
       " 'zloty | poland ',\n",
       " 'hundred  | denominations',\n",
       " 'thousand',\n",
       " 'million',\n",
       " 'billion',\n",
       " 'trillion',\n",
       " 'date  | time related',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'annum',\n",
       " 'year',\n",
       " 'yearly',\n",
       " 'quarter',\n",
       " 'quarterly',\n",
       " 'qtr',\n",
       " 'month',\n",
       " 'monthly',\n",
       " 'week',\n",
       " 'weekly',\n",
       " 'day',\n",
       " 'daily',\n",
       " 'january  | calendar',\n",
       " 'february',\n",
       " 'march',\n",
       " 'april',\n",
       " 'may',\n",
       " 'june',\n",
       " 'july',\n",
       " 'august',\n",
       " 'september',\n",
       " 'october',\n",
       " 'november',\n",
       " 'december',\n",
       " 'jan',\n",
       " 'feb',\n",
       " 'mar',\n",
       " 'apr',\n",
       " 'may',\n",
       " 'jun',\n",
       " 'jul',\n",
       " 'aug',\n",
       " 'sep',\n",
       " 'sept',\n",
       " 'oct',\n",
       " 'nov',\n",
       " 'dec',\n",
       " 'monday',\n",
       " 'tuesday',\n",
       " 'wednesday',\n",
       " 'thursday',\n",
       " 'friday',\n",
       " 'saturday',\n",
       " 'sunday',\n",
       " 'one  | numbers',\n",
       " 'two',\n",
       " 'three',\n",
       " 'four',\n",
       " 'five',\n",
       " 'six',\n",
       " 'seven',\n",
       " 'eight',\n",
       " 'nine',\n",
       " 'ten',\n",
       " 'eleven',\n",
       " 'twelve',\n",
       " 'thirteen',\n",
       " 'fourteen',\n",
       " 'fifteen',\n",
       " 'sixteen',\n",
       " 'seventeen',\n",
       " 'eighteen',\n",
       " 'nineteen',\n",
       " 'twenty',\n",
       " 'thirty',\n",
       " 'forty',\n",
       " 'fifty',\n",
       " 'sixty',\n",
       " 'seventy',\n",
       " 'eighty',\n",
       " 'ninety',\n",
       " 'first',\n",
       " 'second',\n",
       " 'third',\n",
       " 'fourth',\n",
       " 'fifth',\n",
       " 'sixth',\n",
       " 'seventh',\n",
       " 'eighth',\n",
       " 'ninth',\n",
       " 'tenth',\n",
       " 'i  | roman numerals',\n",
       " 'ii',\n",
       " 'iii',\n",
       " 'iv',\n",
       " 'v',\n",
       " 'vi',\n",
       " 'vii',\n",
       " 'viii',\n",
       " 'ix',\n",
       " 'x',\n",
       " 'xi',\n",
       " 'xii',\n",
       " 'xiii',\n",
       " 'xiv',\n",
       " 'xv',\n",
       " 'xvi',\n",
       " 'xvii',\n",
       " 'xviii',\n",
       " 'xix',\n",
       " 'x',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'all',\n",
       " 'am',\n",
       " 'among',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'me',\n",
       " 'more',\n",
       " 'most',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'same',\n",
       " 'she',\n",
       " 'should',\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 'very',\n",
       " 'was',\n",
       " 'we',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'with',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselve',\n",
       " 'a',\n",
       " \"a's\",\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " \"c'mon\",\n",
       " \"c's\",\n",
       " 'came',\n",
       " 'can',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " 'currently',\n",
       " 'd',\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'done',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'h',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he's\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'known',\n",
       " 'l',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'mainly',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'p',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provides',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " \"t's\",\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'thats',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'uucp',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " \"won't\",\n",
       " 'wonder',\n",
       " 'would',\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'z',\n",
       " 'zer',\n",
       " 'united  | geographic',\n",
       " 'state',\n",
       " 'north',\n",
       " 'south',\n",
       " 'east',\n",
       " 'northeast',\n",
       " 'northwest',\n",
       " 'southeast',\n",
       " 'southwest',\n",
       " 'west',\n",
       " 'ocean',\n",
       " 'sea',\n",
       " 'lake',\n",
       " 'river',\n",
       " 'creek',\n",
       " 'gulf',\n",
       " 'mountain',\n",
       " 'street',\n",
       " 'boulevard',\n",
       " 'blvd',\n",
       " 'parkway',\n",
       " 'city',\n",
       " 'county',\n",
       " 'country',\n",
       " 'pacific',\n",
       " 'atlantic',\n",
       " 'indian',\n",
       " 'mediterranean',\n",
       " 'commonwealth',\n",
       " 'america',\n",
       " 'american',\n",
       " 'york  | cities',\n",
       " 'chicago',\n",
       " 'las',\n",
       " 'vegas',\n",
       " 'los',\n",
       " 'angeles',\n",
       " 'milwaukee',\n",
       " 'sunnyvale',\n",
       " 'fremont',\n",
       " 'cincinnati',\n",
       " 'philadelphia',\n",
       " 'miami',\n",
       " 'dallas',\n",
       " 'fort',\n",
       " 'boston',\n",
       " 'houston',\n",
       " 'washington',\n",
       " 'atlanta',\n",
       " 'detroit',\n",
       " 'san',\n",
       " 'fransico',\n",
       " 'phoenix',\n",
       " 'seattle',\n",
       " 'diego',\n",
       " 'minneapolis',\n",
       " 'memphis',\n",
       " 'denver',\n",
       " 'st',\n",
       " 'louis',\n",
       " 'pittsburgh',\n",
       " 'manhattan',\n",
       " 'hollywood',\n",
       " 'columbus',\n",
       " 'indianapolis',\n",
       " 'mumbai',\n",
       " 'karachi',\n",
       " 'ontario',\n",
       " 'toronto',\n",
       " 'cambridge',\n",
       " 'delhi',\n",
       " 'sao',\n",
       " 'paulo',\n",
       " 'shanghai',\n",
       " 'moscow',\n",
       " 'seoul',\n",
       " 'istanbul',\n",
       " 'tokyo',\n",
       " 'jakarta',\n",
       " 'beijing',\n",
       " 'london',\n",
       " 'luxembourg',\n",
       " 'singapore',\n",
       " 'republic  | countries',\n",
       " 'china',\n",
       " 'india',\n",
       " 'indonesia',\n",
       " 'brazil',\n",
       " 'brazilian',\n",
       " 'pakistan',\n",
       " 'bangladesh',\n",
       " 'russia',\n",
       " 'nigeria',\n",
       " 'nova',\n",
       " 'scotia',\n",
       " 'japan',\n",
       " 'malaysia',\n",
       " 'mexico',\n",
       " 'mexican',\n",
       " 'philippines',\n",
       " 'vietnam',\n",
       " 'germany',\n",
       " 'france',\n",
       " 'korea',\n",
       " 'spain',\n",
       " 'argentina',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words_list=[]\n",
    "def stop_words(path):\n",
    "    with open(path,\"r\",encoding='ISO-8859-1') as file:\n",
    "        for line in file:\n",
    "            stop_words_list.append(str(line[:-1]).lower())\n",
    "\n",
    "file_path1=\"StopWords_Auditor.txt\"\n",
    "file_path2=\"StopWords_Currencies.txt\"\n",
    "file_path3=\"StopWords_DatesandNumbers.txt\"\n",
    "file_path4=\"StopWords_Generic.txt\"\n",
    "file_path5=\"StopWords_GenericLong.txt\"\n",
    "file_path6=\"StopWords_Geographic.txt\"\n",
    "file_path7=\"StopWords_Names.txt\"\n",
    "\n",
    "stop_words(file_path1)\n",
    "stop_words(file_path2)\n",
    "stop_words(file_path3)\n",
    "stop_words(file_path4)\n",
    "stop_words(file_path5)\n",
    "stop_words(file_path6)\n",
    "stop_words(file_path7)\n",
    "\n",
    "stop_words_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcde507",
   "metadata": {},
   "source": [
    "# Removing all stopwords(using stop_words_list) from positive dictionary and negative dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "11e90751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2006\n",
      "4783\n",
      "\n",
      "\n",
      "1916\n",
      "4695\n"
     ]
    }
   ],
   "source": [
    "posi_dic=[]\n",
    "nega_dic=[]\n",
    "def pos_dic(path):\n",
    "    with open(path,\"r\",encoding='ISO-8859-1') as file:\n",
    "        for line in file:\n",
    "            posi_dic.append(str(line[:-1]))\n",
    "\n",
    "def neg_dic(path):\n",
    "    with open(path,\"r\",encoding='ISO-8859-1') as file:\n",
    "        for line in file:\n",
    "            nega_dic.append(str(line[:-1]))\n",
    "\n",
    "pos_path=\"/Users/aryan/Documents/xcode/projects/Intern/blackcoffer/MasterDictionary/positive-words.txt\"\n",
    "neg_path=\"/Users/aryan/Documents/xcode/projects/Intern/blackcoffer/MasterDictionary/negative-words.txt\"\n",
    "pos_dic(pos_path)\n",
    "neg_dic(neg_path)\n",
    "print(len(posi_dic))\n",
    "print(len(nega_dic))\n",
    "print(\"\\n\")\n",
    "\n",
    "for i in posi_dic:\n",
    "    if i in stop_words_list:\n",
    "        posi_dic.remove(i)\n",
    "for i in nega_dic:\n",
    "    if i in stop_words_list:\n",
    "        nega_dic.remove(i)\n",
    "print(len(posi_dic))\n",
    "print(len(nega_dic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a0ee00",
   "metadata": {},
   "source": [
    "# Checking the data scraped from website "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32d1614d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP-based Approach for Data TransformationAn ETL tool to pull data from Shiphero to Google Bigquery Data WarehousePlaid Financial Analytics – A Data-Driven Dashboard to generate insightsRecommendation Engine for Insurance Sector to Expand Business in the Rural AreaGrafana Dashboard – Oscar AwardsAutoGPT SetupPlaystore & Appstore to Google Analytics (GA) or Firebase to Google Data Studio Mobile App KPI DashboardGoogle Local Service Ads LSA API To Google BigQuery to Google Data StudioRise of telemedicine and its Impact on Livelihood by 2040Rise of e-health and its impact on humans by the year 2030Rise of e-health and its impact on humans by the year 2030Rise of telemedicine and its Impact on Livelihood by 2040AI/ML and Predictive ModelingSolution for Contact Centre ProblemsHow to Setup Custom Domain for Google App Engine Application?Code Review ChecklistIntroduction“If anything kills over 10 million people in the next few decades, it will be a highly infectious virus rather than a war. Not missiles but microbes.” Bill Gates’s remarks at a TED conference in 2014, right after the world had avoided the Ebola outbreak. When the new, unprecedented, invisible virus hit us, it met an overwhelmed and unprepared healthcare system and oblivious population. This public health emergency demonstrated our lack of scientific consideration and underlined the alarming need for robust innovations in our health and medical facilities. For the past few years, artificial intelligence has proven to be of tangible potential in the healthcare sectors, clinical practices, translational medical and biomedical research.After the first case was detected in China on December 31st 2019, it was an AI program developed by BlueDot that alerted the world about the pandemic. It was quick to realise AI’s ability to analyse large chunks of data could help in detecting patterns and identifying and tracking the possible carriers of the virus.Many tracing apps use AI to keep tabs on the people who have been infected and prevent the risk of cross-infection by using AI algorithms that can track patterns and extract some features to classify or categorise them.So how does AI do that?IBM Watson, a sophisticated AI that works on cloud computing and natural language processing, has prominently contributed to the healthcare sector on a global level. Being a conversational AI, since 2013, Watson has helped in recommending treatments to patients suffering from cancer to ensure that they get the best treatment at optimum costs.Researchers at Google Inc. showed that an AI system can be trained on thousands of images to achieve physician-level sensitivity.By identifying the molecular patterns associated with disease status and its subtypes, gene expression, and protein abundance levels, machine learning methods can detect fatal diseases like cancer at an early stage. Machine Learning (ML) techniques focus mainly on analyzing structured data, which can further help in clustering patients’ traits and infer the probability of disease outcomes. Since patient traits mainly include masses of data relating to age, gender, disease history, disease-specific data like diagnostic imaging and gene expressions, etc, ML can extract features from these data inputs by constructing data analytical algorithms.ML algorithms are either supervised or unsupervised. Unsupervised learning helps in extracting features and clustering similar features together that further leads to early detection of diseases. Clustering and principal component analysis enable grouping or clustering of similar traits together that are further used to maximize or minimize the similarity between the patients within or between the clusters. Since patient traits are recorded in multiple dimensions, such as genes, principal component analysis(PCA) creates the apparatus to reduce these dimensions which humans could have not done alone.Supervised learning considers the outcomes of the subjects together with the traits, and further correlates the inputs with the outputs to predict the probability of getting a particular clinical event, expected value of a disease level or expected survival time, or risk of Down’s syndrome.Biomarker panels that are mostly used to detect ovarian cancer, have outperformed the conventional statistical methods due to machine learning. In addition to this, the use of EHRs and Bayesian networks, which are a part of supervised machine learning algorithms, can predict clinical outcomes and mortality respectively.Unstructured data such as clinical notes and texts are converted into machine-readable structured data with the help of natural language processing(NLP). NLP works with two components: text processing and classification. Text processing helps in identifying a series of disease-relevant keywords in clinical notes and then through classification are further categorized into normal and abnormal cases. Chest screening through ML and NLP has helped find abnormalities in the lungs and provide treatment to covid patients. Healthcare organizations use NLP-based chatbots to increase interactions with patients, keeping their mental health and wellness in check.Deep learning is a modern extension of the classical neural network techniques which helps explore more complex non-linear patterns in data, using algorithms like convolution neural network, recurrent neural network, deep belief network, and deep neural network which enables more accurate clinical prediction. When it comes to genome interpretation, deep neural networks surpass the conventional methods of logistics regression and support vector machines.Sepsis Watch is an AI system trained in deep learning algorithms that holds the capability to analyze over 32 million data points to create a patient’s risk score and identify the early stages of sepsis.Another method known as the Learning-based Optimization of the Under Sampling Pattern( LOUPE) is based on integrating full resolution MRI scans with the convolutional neural network algorithm, which helps in creating more accurate reconstructions.Robotic surgery is widely considered in most delicate surgeries like gynaecology and prostate surgery. Even after striking the right balance between human decisions and AI precision, robotic surgery reduces surgeon efficiency as they have to be manually operated through a console. Thus, autonomous robotic surgery is on the rise with inventions such as robotic silicon fingers that mimic the sense of touch that surgeons need to identify organs, cut tissues, etc., or robotic catheters that can navigate whether it is touching blood, tissue, or valve.Researchers at Children’s National Hospital, Washington have already developed an AI called Smart Tissue Autonomous Robot (STAR), which performs a colon anastomosis on its own with the help of an ML-powered suturing tool, that automatically detects the patient’s breathing pattern to apply suture at the correct point.Cloud computing in healthcare has helped in retrieving and sharing medical records safely with a reduction in maintenance costs. Through this technology doctors and various healthcare workers have access to detailed patient data that helps in speeding up analysis ultimately leading to better care in the form of more accurate information, medications, and therapies.How can It help in Biomedical research?Since AI can analyze literature beyond readability, it can be used to concise biomedical research. With the help of ML algorithms and NLP, AI can accelerate screening and indexing of biomedical research, by ranking the literature of interest which allows researchers to formulate and test scientific hypotheses far more precisely and quickly. Taking it to the next level, AI systems like the computational modelling assistant (CMA) helps researchers to construct simulation models from the concepts they have in mind. Such innovations have majorly contributed to topics such as tumour suppressor mechanisms and protein-protein interaction information extraction.AI as precision medicineSince precision medicine focuses on healthcare interventions to individuals or groups of patients based on their profile, the various AI devices pave the way to practice it more efficiently. With the help of ML, complex algorithms like large datasets can be used to predict and create an optimal treatment strategy.Deep learning and neural networks can be used to process data in healthcare apps and keep a close watch on the patient’s emotional state, food intake, or health monitoring. “Omics” refers to the collective technologies that help in exploring the roles, relationships of various branches ending with the suffix “omics” such as genomics, proteomics, etc. Omics-based tests based on machine learning algorithms help find correlations and predict treatment responses, ultimately creating personalized treatments for individual patients. How it helps in psychology and neuro patientsFor psychologists studying creativity,  AI is promising new classes of experiments that are developing data structures and programs and exploring novel theories on a new horizon. Studies show that  AI can conduct therapy sessions, e-therapy sessions, and assessments autonomously, also assisting human practitioners before, during, or after sessions. The Detection and Computational Analysis of Psychological Signal project uses ML, computer vision, and NLP to analyze language, physical gestures, and social signals to identify cues for human distress. This ground-breaking technology assesses soldiers returning from combat and recognizes those who require further mental health support. In the future, it will combine data captured during face-to-face interviews with information on sleeping, eating, and online behaviours for a complete patient view.Stroke identificationStroke is another frequently occurring disease that affects more than 500 million people worldwide. Thrombus,  in the vessel cerebral infarction is the major (about 85%) cause of stroke occurrence. In recent years, AI techniques have been used in numerous stroke-related studies as early detection and timely treatment along with efficient outcome prediction can help solve the problem. With AI at our disposal, large amounts of data with rich information, more complications and real-life clinical questions can be addressed in this arena. Currently, two ML algorithms- genetic fuzzy finite state machine and PCA were implemented to build a model building solution. These include a human activity recognition stage and a stroke onset detection stage. An alert stroke message is activated as soon as a movement significantly different from the normal pattern is recorded. ML methods have been applied to neuroimaging data to assist disease evaluation and predicting stroke treatment for the diagnosis.Patient MonitoringToday, the market for AI-based patient monitoring is impressive and monetarily enticing. It is evolving with artificial sensors, smart technologies and explores everything from brain-computer interfaces to nanorobotics. Companies with their smart-watches have engaged people to perform remote monitoring even when they are not “patients”. An obvious place to start is with wearable and embedded sensors, glucose monitors, pulse monitors, oximeters, and ECG monitors. With patient monitoring becoming crucial, AI finds numerous applications in chronic conditions, intensive care units, operating rooms, emergency rooms, and cardiac wards where timeless clinical decision-making can be measured in seconds. More advances have started to gain traction like smart prosthetics and implants. These play an impeccable role in patient management post-surgery or rehabilitation. Demographics, laboratory results and vital signs can also be used to predict cardiac arrest, transfer into the intensive care unit, or even death. In addition, an interpretable machine-learning model can assist anesthesiologists in predicting hypoxaemia events during surgery. This suggests that with deep-learning algorithms, raw patient-monitoring data could be better used to avoid information overload and alert overload while enabling more accurate clinical prediction and timely decision-making. ConclusionConsidering the vast range of tasks that an AI can do, it is evident that it holds deep potential in improving patient outcomes to skyrocketing levels. Using sophisticated algorithms AI can bring a revolution in the healthcare sector. Even after facing challenges like whether the technology will be able to deliver the promises, ethical measures, training physicians to use it, standard regulations etc, the role of AI in transforming the clinical practices cannot be ignored. The biggest challenge is the integration of AI in daily practice. All of these can be overcome and within that period the technologies will mature making the system far more enhanced and effective.We provide intelligence, accelerate innovation and implement technology with extraordinary breadth and depth global insights into the big data,data-driven dashboards, applications development, and information management for organizations through combining unique, specialist services and high-lvel human expertise.Contact us: hello@blackcoffer.com© All Right Reserved, Blackcoffer(OPC) Pvt. Ltd\n",
      "\n",
      "\n",
      "['NLP-based', 'Approach', 'Data', 'TransformationAn', 'ETL', 'tool', 'pull', 'data', 'Shiphero', 'Google', 'Bigquery', 'Data', 'WarehousePlaid', 'Financial', 'Analytics', '–', 'A', 'Data-Driven', 'Dashboard', 'generate', 'insightsRecommendation', 'Engine', 'Insurance', 'Sector', 'Expand', 'Business', 'Rural', 'AreaGrafana', 'Dashboard', '–', 'Oscar', 'AwardsAutoGPT', 'SetupPlaystore', '&', 'Appstore', 'Google', 'Analytics', '(GA)', 'Firebase', 'Google', 'Data', 'Studio', 'Mobile', 'App', 'KPI', 'DashboardGoogle', 'Local', 'Service', 'Ads', 'LSA', 'API', 'To', 'Google', 'BigQuery', 'Google', 'Data', 'StudioRise', 'telemedicine', 'its', 'Impact', 'Livelihood', '2040Rise', 'e-health', 'its', 'impact', 'humans', '2030Rise', 'e-health', 'its', 'impact', 'humans', '2030Rise', 'telemedicine', 'its', 'Impact', 'Livelihood', '2040AI/ML', 'Predictive', 'ModelingSolution', 'Contact', 'Centre', 'ProblemsHow', 'Setup', 'Custom', 'Domain', 'Google', 'App', 'Engine', 'Application?Code', 'Review', 'ChecklistIntroduction“If', 'kills', '10', 'people', 'decades', 'highly', 'infectious', 'virus', 'than', 'war', 'Not', 'missiles', 'microbes.”', 'Bill', 'Gates’s', 'remarks', 'TED', 'conference', '2014', 'world', 'avoided', 'Ebola', 'outbreak', 'When', 'unprecedented', 'invisible', 'virus', 'hit', 'met', 'overwhelmed', 'unprepared', 'healthcare', 'system', 'oblivious', 'population', 'This', 'public', 'health', 'emergency', 'demonstrated', 'lack', 'scientific', 'consideration', 'underlined', 'alarming', 'robust', 'innovations', 'our', 'health', 'medical', 'facilities', 'For', 'past', 'few', 'years', 'artificial', 'intelligence', 'proven', 'tangible', 'potential', 'healthcare', 'sectors', 'clinical', 'practices', 'translational', 'medical', 'biomedical', 'research.After', 'first', 'detected', 'China', 'December', '31st', '2019', 'was', 'AI', 'program', 'developed', 'BlueDot', 'alerted', 'world', 'pandemic', 'It', 'was', 'quick', 'realise', 'AI’s', 'ability', 'analyse', 'chunks', 'data', 'detecting', 'patterns', 'identifying', 'tracking', 'possible', 'carriers', 'virus.Many', 'tracing', 'apps', 'AI', 'keep', 'tabs', 'people', 'infected', 'prevent', 'risk', 'cross-infection', 'AI', 'algorithms', 'track', 'patterns', 'extract', 'features', 'classify', 'categorise', 'them.So', 'does', 'AI', 'that?IBM', 'Watson', 'sophisticated', 'AI', 'works', 'cloud', 'computing', 'natural', 'language', 'processing', 'prominently', 'contributed', 'healthcare', 'sector', 'global', 'level', 'Being', 'conversational', 'AI', '2013', 'Watson', 'helped', 'recommending', 'treatments', 'patients', 'suffering', 'cancer', 'ensure', 'treatment', 'optimum', 'costs.Researchers', 'Google', 'Inc', 'showed', 'AI', 'system', 'trained', 'thousands', 'images', 'achieve', 'physician-level', 'sensitivity.By', 'identifying', 'molecular', 'patterns', 'disease', 'status', 'its', 'subtypes', 'expression', 'protein', 'abundance', 'levels', 'machine', 'learning', 'methods', 'detect', 'fatal', 'diseases', 'cancer', 'stage', 'Machine', 'Learning', '(ML)', 'techniques', 'focus', 'analyzing', 'structured', 'data', 'clustering', 'patients’', 'traits', 'infer', 'probability', 'disease', 'outcomes', 'Since', 'patient', 'traits', 'include', 'masses', 'data', 'relating', 'age', 'gender', 'disease', 'history', 'disease-specific', 'data', 'diagnostic', 'imaging', 'gene', 'expressions', 'ML', 'extract', 'features', 'data', 'inputs', 'constructing', 'data', 'analytical', 'algorithms.ML', 'algorithms', 'either', 'supervised', 'unsupervised', 'Unsupervised', 'learning', 'helps', 'extracting', 'features', 'clustering', 'similar', 'features', 'leads', 'early', 'detection', 'diseases', 'Clustering', 'principal', 'component', 'analysis', 'enable', 'grouping', 'clustering', 'similar', 'traits', 'maximize', 'minimize', 'similarity', 'patients', 'clusters', 'Since', 'patient', 'traits', 'recorded', 'multiple', 'dimensions', 'genes', 'principal', 'component', 'analysis(PCA)', 'creates', 'apparatus', 'reduce', 'these', 'dimensions', 'humans', 'done', 'alone.Supervised', 'learning', 'considers', 'outcomes', 'subjects', 'traits', 'further', 'correlates', 'inputs', 'outputs', 'predict', 'probability', 'getting', 'particular', 'clinical', 'event', 'expected', 'disease', 'level', 'expected', 'survival', 'time', 'risk', 'Down’s', 'syndrome.Biomarker', 'panels', 'detect', 'ovarian', 'cancer', 'outperformed', 'conventional', 'statistical', 'methods', 'due', 'machine', 'learning', 'In', 'addition', 'EHRs', 'Bayesian', 'networks', 'part', 'supervised', 'machine', 'learning', 'algorithms', 'predict', 'clinical', 'outcomes', 'mortality', 'respectively.Unstructured', 'data', 'clinical', 'notes', 'texts', 'are', 'converted', 'machine-readable', 'structured', 'data', 'natural', 'language', 'processing(NLP)', 'NLP', 'works', 'components:', 'text', 'processing', 'classification', 'Text', 'processing', 'helps', 'identifying', 'series', 'disease-relevant', 'keywords', 'clinical', 'notes', 'then', 'classification', 'are', 'further', 'categorized', 'normal', 'abnormal', 'cases', 'Chest', 'screening', 'ML', 'NLP', 'helped', 'find', 'abnormalities', 'lungs', 'provide', 'treatment', 'covid', 'patients', 'Healthcare', 'organizations', 'use', 'NLP-based', 'chatbots', 'increase', 'interactions', 'patients', 'keeping', 'mental', 'health', 'wellness', 'check.Deep', 'learning', 'modern', 'extension', 'classical', 'neural', 'network', 'techniques', 'helps', 'explore', 'complex', 'non-linear', 'patterns', 'data', 'using', 'algorithms', 'convolution', 'neural', 'network', 'recurrent', 'neural', 'network', 'deep', 'belief', 'network', 'deep', 'neural', 'network', 'enables', 'accurate', 'clinical', 'prediction', 'When', 'comes', 'genome', 'interpretation', 'deep', 'neural', 'networks', 'surpass', 'conventional', 'methods', 'logistics', 'regression', 'support', 'vector', 'machines.Sepsis', 'Watch', 'AI', 'system', 'trained', 'deep', 'learning', 'algorithms', 'holds', 'capability', 'analyze', '32', 'data', 'points', 'create', 'patient’s', 'risk', 'score', 'identify', 'early', 'stages', 'sepsis.Another', 'method', 'Learning-based', 'Optimization', 'Under', 'Sampling', 'Pattern(', 'LOUPE)', 'based', 'integrating', 'full', 'resolution', 'MRI', 'scans', 'convolutional', 'neural', 'network', 'algorithm', 'helps', 'creating', 'accurate', 'reconstructions.Robotic', 'surgery', 'widely', 'considered', 'most', 'delicate', 'surgeries', 'gynaecology', 'prostate', 'surgery', 'Even', 'striking', 'right', 'balance', 'human', 'decisions', 'AI', 'precision', 'robotic', 'surgery', 'reduces', 'surgeon', 'efficiency', 'manually', 'operated', 'console', 'Thus', 'autonomous', 'robotic', 'surgery', 'rise', 'inventions', 'robotic', 'silicon', 'fingers', 'mimic', 'sense', 'touch', 'surgeons', 'identify', 'organs', 'cut', 'tissues', 'etc.', 'robotic', 'catheters', 'navigate', 'touching', 'tissue', 'valve.Researchers', 'Children’s', 'National', 'Hospital', 'Washington', 'already', 'developed', 'AI', 'called', 'Smart', 'Tissue', 'Autonomous', 'Robot', '(STAR)', 'performs', 'a', 'colon', 'anastomosis', 'its', 'the', 'help', 'an', 'ML-powered', 'suturing', 'tool', 'automatically', 'detects', 'the', 'patient’s', 'breathing', 'pattern', 'apply', 'suture', 'the', 'correct', 'point.Cloud', 'computing', 'healthcare', 'helped', 'retrieving', 'sharing', 'medical', 'records', 'safely', 'a', 'reduction', 'maintenance', 'costs', 'Through', 'this', 'technology', 'doctors', 'various', 'healthcare', 'workers', 'access', 'detailed', 'patient', 'data', 'helps', 'speeding', 'analysis', 'ultimately', 'leading', 'care', 'the', 'form', 'accurate', 'information', 'medications', 'therapies.How', 'It', 'help', 'Biomedical', 'research?Since', 'AI', 'analyze', 'literature', 'readability', 'be', 'concise', 'biomedical', 'research', 'With', 'the', 'help', 'ML', 'algorithms', 'NLP', 'AI', 'accelerate', 'screening', 'indexing', 'biomedical', 'research', 'ranking', 'the', 'literature', 'interest', 'allows', 'researchers', 'formulate', 'test', 'scientific', 'hypotheses', 'precisely', 'quickly', 'Taking', 'the', 'next', 'level', 'AI', 'systems', 'the', 'computational', 'modelling', 'assistant', '(CMA)', 'helps', 'researchers', 'construct', 'simulation', 'models', 'the', 'concepts', 'they', 'mind', 'Such', 'innovations', 'majorly', 'contributed', 'topics', 'as', 'tumour', 'suppressor', 'mechanisms', 'protein-protein', 'interaction', 'information', 'extraction.AI', 'as', 'precision', 'medicineSince', 'precision', 'medicine', 'focuses', 'healthcare', 'interventions', 'individuals', 'groups', 'patients', 'based', 'their', 'profile', 'the', 'various', 'AI', 'devices', 'pave', 'the', 'way', 'practice', 'efficiently', 'With', 'the', 'help', 'ML', 'complex', 'algorithms', 'datasets', 'be', 'predict', 'create', 'an', 'optimal', 'treatment', 'strategy.Deep', 'learning', 'neural', 'networks', 'be', 'used', 'process', 'data', 'healthcare', 'apps', 'keep', 'a', 'close', 'watch', 'the', 'patient’s', 'emotional', 'food', 'intake', 'health', 'monitoring.\\xa0“Omics”', 'refers', 'the', 'collective', 'technologies', 'help', 'exploring', 'the', 'roles', 'relationships', 'various', 'branches', 'ending', 'the', 'suffix', '“omics”', 'as', 'genomics', 'proteomics', 'Omics-based', 'tests', 'based', 'machine', 'learning', 'algorithms', 'help', 'find', 'correlations', 'predict', 'treatment', 'responses', 'ultimately', 'creating', 'personalized', 'treatments', 'individual', 'patients.\\xa0How', 'helps', 'psychology', 'neuro', 'patientsFor', 'psychologists', 'studying', 'creativity,\\xa0', 'AI', 'promising', 'classes', 'experiments', 'are', 'developing', 'data', 'structures', 'programs', 'exploring', 'theories', 'on', 'a', 'new', 'horizon', 'Studies', 'show', '\\xa0AI', 'conduct', 'therapy', 'e-therapy', 'assessments', 'autonomously', 'assisting', 'human', 'practitioners', 'after', 'The', 'Detection', 'Computational', 'Analysis', 'Psychological', 'Signal', 'project', 'ML', 'computer', 'vision', 'NLP', 'analyze', 'language', 'physical', 'gestures', 'social', 'signals', 'identify', 'cues', 'human', 'distress', 'This', 'ground-breaking', 'technology', 'assesses', 'soldiers', 'returning', 'combat', 'recognizes', 'who', 'require', 'further', 'mental', 'health', 'support', 'In', 'the', 'future', 'combine', 'data', 'captured', 'face-to-face', 'interviews', 'information', 'on', 'sleeping', 'eating', 'online', 'behaviours', 'a', 'complete', 'patient', 'view.Stroke', 'identificationStroke', 'another', 'frequently', 'occurring', 'disease', 'affects', 'more', 'than', '500', 'people', 'worldwide', 'Thrombus,\\xa0', 'the', 'vessel', 'cerebral', 'infarction', 'the', '(about', '85%)', 'stroke', 'occurrence', 'In', 'recent', 'years', 'AI', 'techniques', 'been', 'used', 'numerous', 'stroke-related', 'studies', 'as', 'early', 'detection', 'timely', 'treatment', 'efficient', 'outcome', 'prediction', 'help', 'solve', 'the', 'problem', 'With', 'AI', 'our', 'disposal', 'large', 'amounts', 'data', 'with', 'rich', 'information', 'more', 'complications', 'real-life', 'clinical', 'questions', 'be', 'addressed', 'this', 'Currently', 'two', 'ML', 'algorithms-', 'genetic', 'fuzzy', 'finite', 'machine', 'PCA', 'implemented', 'build', 'a', 'model', 'building', 'solution', 'These', 'include', 'a', 'human', 'activity', 'recognition', 'stage', 'a', 'stroke', 'onset', 'detection', 'stage', 'An', 'alert', 'stroke', 'message', 'activated', 'as', 'soon', 'as', 'a', 'movement', 'significantly', 'from', 'the', 'normal', 'pattern', 'recorded', 'ML', 'methods', 'have', 'been', 'applied', 'neuroimaging', 'data', 'assist', 'disease', 'evaluation', 'predicting', 'stroke', 'treatment', 'the', 'diagnosis.Patient', 'MonitoringToday', 'the', 'market', 'AI-based', 'patient', 'monitoring', 'impressive', 'monetarily', 'enticing', 'It', 'evolving', 'with', 'artificial', 'sensors', 'technologies', 'explores', 'from', 'brain-computer', 'interfaces', 'nanorobotics', 'Companies', 'with', 'their', 'smart-watches', 'have', 'engaged', 'people', 'to', 'perform', 'remote', 'monitoring', 'when', 'they', 'are', '“patients”', 'An', 'obvious', 'to', 'start', 'with', 'wearable', 'embedded', 'sensors', 'glucose', 'monitors', 'pulse', 'monitors', 'oximeters', 'ECG', 'monitors', 'With', 'patient', 'monitoring', 'crucial', 'AI', 'finds', 'numerous', 'applications', 'chronic', 'conditions', 'intensive', 'care', 'units', 'operating', 'rooms', 'emergency', 'rooms', 'cardiac', 'wards', 'timeless', 'clinical', 'decision-making', 'be', 'measured', 'seconds', 'More', 'advances', 'have', 'started', 'to', 'gain', 'traction', 'smart', 'prosthetics', 'implants', 'These', 'play', 'an', 'impeccable', 'role', 'patient', 'management', 'post-surgery', 'rehabilitation', 'Demographics', 'laboratory', 'results', 'vital', 'signs', 'also', 'be', 'used', 'to', 'predict', 'cardiac', 'arrest', 'transfer', 'the', 'intensive', 'care', 'unit', 'or', 'even', 'death', 'In', 'addition', 'an', 'interpretable', 'machine-learning', 'model', 'can', 'assist', 'anesthesiologists', 'predicting', 'hypoxaemia', 'events', 'during', 'surgery', 'This', 'suggests', 'with', 'deep-learning', 'algorithms', 'raw', 'patient-monitoring', 'data', 'be', 'better', 'used', 'to', 'avoid', 'information', 'overload', 'alert', 'overload', 'enabling', 'more', 'accurate', 'clinical', 'prediction', 'timely', 'decision-making.\\xa0ConclusionConsidering', 'the', 'vast', 'of', 'tasks', 'an', 'AI', 'can', 'do', 'it', 'evident', 'that', 'it', 'holds', 'deep', 'potential', 'improving', 'patient', 'outcomes', 'to', 'skyrocketing', 'levels', 'Using', 'sophisticated', 'algorithms', 'AI', 'can', 'bring', 'a', 'revolution', 'the', 'healthcare', 'sector', 'Even', 'after', 'facing', 'challenges', 'whether', 'the', 'technology', 'will', 'be', 'to', 'deliver', 'the', 'promises', 'ethical', 'measures', 'training', 'physicians', 'to', 'use', 'it', 'standard', 'regulations', 'the', 'role', 'of', 'AI', 'in', 'transforming', 'the', 'clinical', 'practices', 'be', 'The', 'biggest', 'challenge', 'is', 'the', 'integration', 'of', 'AI', 'in', 'daily', 'practice', 'All', 'of', 'these', 'can', 'be', 'overcome', 'within', 'that', 'period', 'the', 'technologies', 'will', 'mature', 'making', 'the', 'system', 'more', 'enhanced', 'effective.We', 'provide', 'intelligence', 'accelerate', 'innovation', 'implement', 'technology', 'with', 'extraordinary', 'breadth', 'depth', 'global', 'insights', 'the', 'big', 'data,data-driven', 'dashboards', 'applications', 'development', 'information', 'management', 'for', 'organizations', 'combining', 'unique', 'specialist', 'services', 'and', 'high-lvel', 'human', 'expertise.Contact', 'us:', 'hello@blackcoffer.com©', 'All', 'Right', 'Reserved', 'Blackcoffer(OPC)', 'Pvt', 'Ltd']\n",
      "\n",
      "\n",
      "AI in healthcare to Improve Patient Outcomes\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://insights.blackcoffer.com/ai-in-healthcare-to-improve-patient-outcomes/\"\n",
    "res = requests.get(url)\n",
    "html_content = res.text\n",
    "soup = BeautifulSoup(html_content,\"html.parser\")\n",
    "paragraphs = soup.find_all(\"p\")\n",
    "article_text = \"\".join([p.get_text() for p in paragraphs])\n",
    "headers = soup.find_all(\"h1\")\n",
    "article_head = \"\".join([h.get_text() for h in headers])\n",
    "art_txt = list(article_text.split(\" \"))\n",
    "print(article_text)\n",
    "print(\"\\n\")\n",
    "for i in range(len(art_txt)):\n",
    "    a=art_txt[i]\n",
    "    if a[-1]==\".\" or a[-1]==\",\":\n",
    "        art_txt[i]=a[:-1]\n",
    "\n",
    "for i in art_txt:\n",
    "    if i in stop_words_list:\n",
    "        art_txt.remove(i)\n",
    "print(art_txt)\n",
    "print(\"\\n\")\n",
    "print(article_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8954a2",
   "metadata": {},
   "source": [
    "# Making a function that gives positive_score, negative_score, polarity_score and subjective_score of the website article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e684d3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score,neg_score=0,0\n",
    "def pos_neg_score(url):\n",
    "    pos_score,neg_score=0,0\n",
    "    res = requests.get(url)\n",
    "    html_content = res.text\n",
    "    soup = BeautifulSoup(html_content,\"html.parser\")\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    article_text = \"\".join([p.get_text() for p in paragraphs])\n",
    "    headers = soup.find_all(\"h1\")\n",
    "    article_head = \"\".join([h.get_text() for h in headers])\n",
    "    art_txt = list(article_text.split(\" \"))\n",
    "    for i in range(len(art_txt)):\n",
    "        a=art_txt[i]\n",
    "        if a:\n",
    "            if a[-1]==\".\" or a[-1]==\",\" or a[-1]==\":\" or a[-1]==\";\":\n",
    "                art_txt[i]=a[:-1]\n",
    "    \n",
    "    for i in art_txt:\n",
    "        if i in stop_words_list:\n",
    "            art_txt.remove(i)\n",
    "    \n",
    "    for i in art_txt:\n",
    "        if i in posi_dic:\n",
    "            pos_score+=1\n",
    "        if i in nega_dic:\n",
    "            neg_score+=1\n",
    "    sub_score=(pos_score - neg_score)/(len(art_txt)) + (0.000001)\n",
    "            \n",
    "    pol_score=(pos_score - neg_score)/(pos_score + neg_score) + (0.000001)\n",
    "    return pos_score,neg_score,pol_score,sub_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fcb377",
   "metadata": {},
   "source": [
    "# Adding the positive_score, negative_score, polarity_score and subjective_score to the corresponding website in output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7419e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To take url input and add output in output excel file\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd \n",
    "\n",
    "input_file=pd.read_excel(\"Input.xlsx\",sheet_name='Sheet1')\n",
    "out_path=\"/Users/aryan/Documents/xcode/projects/Intern/blackcoffer/Output/Output Data Structure.xlsx\"\n",
    "outs=load_workbook(out_path,data_only=True)\n",
    "outf=outs[\"Sheet1\"]\n",
    "i=2\n",
    "for url in input_file[\"URL\"]:\n",
    "    p,n,pol,sub=pos_neg_score(url)\n",
    "    #To add output in output excel file\n",
    "    outf.cell(i,3).value=p\n",
    "    outf.cell(i,4).value=n\n",
    "    outf.cell(i,5).value=pol\n",
    "    outf.cell(i,6).value=sub\n",
    "    i+=1\n",
    "    \n",
    "outs.save(out_path)\n",
    "outs.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181019f",
   "metadata": {},
   "source": [
    "# Making a function that gives average_sentence_length, percentage_of_complex_words, fog_index, average_no_of_words_per_sentence, complex_word_count, word_count, syllable_per_word, personal_pronoun_count, average_word_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ad8190c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def word_matter(url):\n",
    "    res = requests.get(url)\n",
    "    html_content = res.text\n",
    "    soup = BeautifulSoup(html_content,\"html.parser\")\n",
    "    paragraphs = soup.find_all(\"p\")\n",
    "    article_text = \"\".join([p.get_text() for p in paragraphs])\n",
    "    art_txt = list(article_text.split(\" \"))\n",
    "\n",
    "\n",
    "    no_of_words=len(art_txt)\n",
    "\n",
    "\n",
    "    #count no of sentences\n",
    "    no_of_sntncs=0\n",
    "    for i in art_txt:\n",
    "        if i:\n",
    "            if i[-1]==\".\":\n",
    "                no_of_sntncs+=1\n",
    "\n",
    "\n",
    "    #Counting the number of Complex Words\n",
    "    vow=[\"a\",\"e\",\"i\",\"o\",\"u\"]\n",
    "    compl_cnt=0\n",
    "    for i in art_txt:\n",
    "        syl=0\n",
    "        for j in i:\n",
    "            j=j.lower()\n",
    "            if j[-2:]==\"es\" or j[-2:]==\"ed\":\n",
    "                break\n",
    "            if j in vow:\n",
    "                syl+=1\n",
    "            if syl>2:\n",
    "                compl_cnt+=1\n",
    "                break\n",
    "\n",
    "    #remove all the stopwords using NLTK and any punctuations\n",
    "    \n",
    "    stp_wrds=set(stopwords.words('english'))\n",
    "    for i in art_txt:\n",
    "        if i in stp_wrds:\n",
    "            art_txt.remove(i)\n",
    "    char_cnt=0\n",
    "    for i in range(len(art_txt)):\n",
    "        a=art_txt[i]\n",
    "        if a:\n",
    "            if a[-1]==\".\" or a[-1]==\",\" or a[-1]==\":\" or a[-1]==\";\" or a[-1]==\"?\" or a[-1]==\"!\":\n",
    "                art_txt[i]=a[:-1]\n",
    "            char_cnt+=len(a)\n",
    "\n",
    "    word_cnt=len(art_txt)\n",
    "\n",
    "    art_txt = list(article_text.split(\" \"))\n",
    "\n",
    "    #Syllable Count Per Word\n",
    "    vow=[\"a\",\"e\",\"i\",\"o\",\"u\"]\n",
    "    syl_cnt=[]\n",
    "    for i in art_txt:\n",
    "        syl=0\n",
    "        for j in i:\n",
    "            j=j.lower()\n",
    "            if j[-2:]==\"es\" or j[-2:]==\"ed\":\n",
    "                break\n",
    "            if j in vow:\n",
    "                syl+=1\n",
    "        syl_cnt.append(syl)\n",
    "    syl_cnt_pr_wrd=max(syl_cnt)\n",
    "\n",
    "    #Personal Pronoun count using regex\n",
    "    \n",
    "    text=article_text.lower()\n",
    "    words_to_count = ['i', 'we', 'my', 'ours', 'us']\n",
    "\n",
    "    pattern = r'\\b(?:' + '|'.join(words_to_count) + r')\\b'\n",
    "\n",
    "    counts = 0\n",
    "    for word in words_to_count:\n",
    "        counts += len(re.findall(r'\\b' + word + r'\\b', text, re.IGNORECASE))\n",
    "\n",
    "    #Average Word Length\n",
    "    art_txt = list(article_text.split(\" \"))\n",
    "    avg_wrd_length=char_cnt/word_cnt\n",
    "\n",
    "\n",
    "    avg_snt_length=no_of_words/no_of_sntncs\n",
    "    prcnt_of_compl_words=compl_cnt/no_of_words\n",
    "    fog_idx=0.4*(avg_snt_length+prcnt_of_compl_words)\n",
    "    avg_words_per_sentence=avg_snt_length\n",
    "    cmplx_word_cnt=compl_cnt\n",
    "    psnl_pron_cnt=counts\n",
    "    return avg_snt_length,prcnt_of_compl_words,fog_idx,avg_words_per_sentence,cmplx_word_cnt,word_cnt,syl_cnt_pr_wrd,psnl_pron_cnt,avg_wrd_length\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252c2378",
   "metadata": {},
   "source": [
    "# Adding average_sentence_length, percentage_of_complex_words, fog_index, average_no_of_words_per_sentence, complex_word_count, word_count, syllable_per_word, personal_pronoun_count, average_word_length to the corresponding website in output_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1eaba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "import pandas as pd \n",
    "\n",
    "input_file=pd.read_excel(\"Input.xlsx\",sheet_name='Sheet1')\n",
    "out_path=\"/Users/aryan/Documents/xcode/projects/Intern/blackcoffer/Output/Output Data Structure.xlsx\"\n",
    "outs=load_workbook(out_path,data_only=True)\n",
    "outf=outs[\"Sheet1\"]\n",
    "i=2\n",
    "for url in input_file[\"URL\"]:\n",
    "    a1,a2,a3,a4,a5,a6,a7,a8,a9=word_matter(url)\n",
    "    #To add output in output excel file\n",
    "    outf.cell(i,7).value=a1\n",
    "    outf.cell(i,8).value=a2\n",
    "    outf.cell(i,9).value=a3\n",
    "    outf.cell(i,10).value=a4\n",
    "    outf.cell(i,11).value=a5\n",
    "    outf.cell(i,12).value=a6\n",
    "    outf.cell(i,13).value=a7\n",
    "    outf.cell(i,14).value=a8\n",
    "    outf.cell(i,15).value=a9\n",
    "    i+=1\n",
    "    \n",
    "outs.save(out_path)\n",
    "outs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a17c98b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>POSITIVE SCORE</th>\n",
       "      <th>NEGATIVE SCORE</th>\n",
       "      <th>POLARITY SCORE</th>\n",
       "      <th>SUBJECTIVITY SCORE</th>\n",
       "      <th>AVG SENTENCE LENGTH</th>\n",
       "      <th>PERCENTAGE OF COMPLEX WORDS</th>\n",
       "      <th>FOG INDEX</th>\n",
       "      <th>AVG NUMBER OF WORDS PER SENTENCE</th>\n",
       "      <th>COMPLEX WORD COUNT</th>\n",
       "      <th>WORD COUNT</th>\n",
       "      <th>SYLLABLE PER WORD</th>\n",
       "      <th>PERSONAL PRONOUNS</th>\n",
       "      <th>AVG WORD LENGTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-in-healthc...</td>\n",
       "      <td>59</td>\n",
       "      <td>30</td>\n",
       "      <td>0.325844</td>\n",
       "      <td>0.021855</td>\n",
       "      <td>37.490196</td>\n",
       "      <td>0.361402</td>\n",
       "      <td>15.140639</td>\n",
       "      <td>37.490196</td>\n",
       "      <td>691</td>\n",
       "      <td>1386</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>7.135642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>https://insights.blackcoffer.com/what-if-the-c...</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>0.230770</td>\n",
       "      <td>0.020732</td>\n",
       "      <td>28.327273</td>\n",
       "      <td>0.258023</td>\n",
       "      <td>11.434118</td>\n",
       "      <td>28.327273</td>\n",
       "      <td>402</td>\n",
       "      <td>1091</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>6.170486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39</td>\n",
       "      <td>https://insights.blackcoffer.com/what-jobs-wil...</td>\n",
       "      <td>67</td>\n",
       "      <td>34</td>\n",
       "      <td>0.326734</td>\n",
       "      <td>0.026830</td>\n",
       "      <td>29.031746</td>\n",
       "      <td>0.344451</td>\n",
       "      <td>11.750479</td>\n",
       "      <td>29.031746</td>\n",
       "      <td>630</td>\n",
       "      <td>1298</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>6.901387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>https://insights.blackcoffer.com/will-machine-...</td>\n",
       "      <td>53</td>\n",
       "      <td>19</td>\n",
       "      <td>0.472223</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>26.227273</td>\n",
       "      <td>0.255921</td>\n",
       "      <td>10.593278</td>\n",
       "      <td>26.227273</td>\n",
       "      <td>443</td>\n",
       "      <td>1213</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>6.133553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>https://insights.blackcoffer.com/will-ai-repla...</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>0.353847</td>\n",
       "      <td>0.018823</td>\n",
       "      <td>36.640000</td>\n",
       "      <td>0.280022</td>\n",
       "      <td>14.768009</td>\n",
       "      <td>36.640000</td>\n",
       "      <td>513</td>\n",
       "      <td>1291</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>6.503486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>42</td>\n",
       "      <td>https://insights.blackcoffer.com/man-and-machi...</td>\n",
       "      <td>42</td>\n",
       "      <td>20</td>\n",
       "      <td>0.354840</td>\n",
       "      <td>0.023785</td>\n",
       "      <td>35.564103</td>\n",
       "      <td>0.273252</td>\n",
       "      <td>14.334942</td>\n",
       "      <td>35.564103</td>\n",
       "      <td>379</td>\n",
       "      <td>985</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>6.344162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>43</td>\n",
       "      <td>https://insights.blackcoffer.com/in-future-or-...</td>\n",
       "      <td>23</td>\n",
       "      <td>11</td>\n",
       "      <td>0.352942</td>\n",
       "      <td>0.020135</td>\n",
       "      <td>22.846154</td>\n",
       "      <td>0.286195</td>\n",
       "      <td>9.252940</td>\n",
       "      <td>22.846154</td>\n",
       "      <td>255</td>\n",
       "      <td>623</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6.608347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>44</td>\n",
       "      <td>https://insights.blackcoffer.com/how-neural-ne...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.022557</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.394444</td>\n",
       "      <td>72.157778</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>71</td>\n",
       "      <td>137</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7.437956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>https://insights.blackcoffer.com/how-machine-l...</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>0.446810</td>\n",
       "      <td>0.036146</td>\n",
       "      <td>29.724138</td>\n",
       "      <td>0.266821</td>\n",
       "      <td>11.996384</td>\n",
       "      <td>29.724138</td>\n",
       "      <td>230</td>\n",
       "      <td>618</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6.223301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46</td>\n",
       "      <td>https://insights.blackcoffer.com/deep-learning...</td>\n",
       "      <td>64</td>\n",
       "      <td>31</td>\n",
       "      <td>0.347369</td>\n",
       "      <td>0.021986</td>\n",
       "      <td>35.261538</td>\n",
       "      <td>0.277051</td>\n",
       "      <td>14.215436</td>\n",
       "      <td>35.261538</td>\n",
       "      <td>635</td>\n",
       "      <td>1582</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>6.312263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47</td>\n",
       "      <td>https://insights.blackcoffer.com/how-to-protec...</td>\n",
       "      <td>43</td>\n",
       "      <td>49</td>\n",
       "      <td>-0.065216</td>\n",
       "      <td>-0.004443</td>\n",
       "      <td>23.376471</td>\n",
       "      <td>0.285858</td>\n",
       "      <td>9.464931</td>\n",
       "      <td>23.376471</td>\n",
       "      <td>568</td>\n",
       "      <td>1429</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6.524843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>48</td>\n",
       "      <td>https://insights.blackcoffer.com/how-machines-...</td>\n",
       "      <td>32</td>\n",
       "      <td>19</td>\n",
       "      <td>0.254903</td>\n",
       "      <td>0.014757</td>\n",
       "      <td>33.589744</td>\n",
       "      <td>0.334351</td>\n",
       "      <td>13.569638</td>\n",
       "      <td>33.589744</td>\n",
       "      <td>438</td>\n",
       "      <td>930</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>6.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-human-robo...</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>0.142858</td>\n",
       "      <td>0.007496</td>\n",
       "      <td>25.660377</td>\n",
       "      <td>0.291176</td>\n",
       "      <td>10.380622</td>\n",
       "      <td>25.660377</td>\n",
       "      <td>396</td>\n",
       "      <td>984</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>6.389228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>https://insights.blackcoffer.com/how-ai-will-c...</td>\n",
       "      <td>55</td>\n",
       "      <td>23</td>\n",
       "      <td>0.410257</td>\n",
       "      <td>0.028370</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>0.260090</td>\n",
       "      <td>22.404036</td>\n",
       "      <td>55.750000</td>\n",
       "      <td>464</td>\n",
       "      <td>1207</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>6.242751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>51</td>\n",
       "      <td>https://insights.blackcoffer.com/future-of-wor...</td>\n",
       "      <td>52</td>\n",
       "      <td>19</td>\n",
       "      <td>0.464790</td>\n",
       "      <td>0.030001</td>\n",
       "      <td>33.877551</td>\n",
       "      <td>0.296988</td>\n",
       "      <td>13.669816</td>\n",
       "      <td>33.877551</td>\n",
       "      <td>493</td>\n",
       "      <td>1159</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>6.644521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>52</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-tool-alexa...</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>41.062500</td>\n",
       "      <td>0.356164</td>\n",
       "      <td>16.567466</td>\n",
       "      <td>41.062500</td>\n",
       "      <td>234</td>\n",
       "      <td>470</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7.155319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53</td>\n",
       "      <td>https://insights.blackcoffer.com/ai-healthcare...</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>0.321740</td>\n",
       "      <td>0.029696</td>\n",
       "      <td>327.666667</td>\n",
       "      <td>0.251780</td>\n",
       "      <td>131.167379</td>\n",
       "      <td>327.666667</td>\n",
       "      <td>495</td>\n",
       "      <td>1338</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>5.915546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>54</td>\n",
       "      <td>https://insights.blackcoffer.com/all-you-need-...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000001</td>\n",
       "      <td>0.028669</td>\n",
       "      <td>36.916667</td>\n",
       "      <td>0.329571</td>\n",
       "      <td>14.898495</td>\n",
       "      <td>36.916667</td>\n",
       "      <td>292</td>\n",
       "      <td>630</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>6.803175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>55</td>\n",
       "      <td>https://insights.blackcoffer.com/evolution-of-...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0.565218</td>\n",
       "      <td>0.022338</td>\n",
       "      <td>44.684211</td>\n",
       "      <td>0.347468</td>\n",
       "      <td>18.012671</td>\n",
       "      <td>44.684211</td>\n",
       "      <td>295</td>\n",
       "      <td>604</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7.226821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56</td>\n",
       "      <td>https://insights.blackcoffer.com/how-data-anal...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>132.149091</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>123</td>\n",
       "      <td>245</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>7.306122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    URL_ID                                                URL  POSITIVE SCORE  \\\n",
       "0       37  https://insights.blackcoffer.com/ai-in-healthc...              59   \n",
       "1       38  https://insights.blackcoffer.com/what-if-the-c...              56   \n",
       "2       39  https://insights.blackcoffer.com/what-jobs-wil...              67   \n",
       "3       40  https://insights.blackcoffer.com/will-machine-...              53   \n",
       "4       41  https://insights.blackcoffer.com/will-ai-repla...              44   \n",
       "5       42  https://insights.blackcoffer.com/man-and-machi...              42   \n",
       "6       43  https://insights.blackcoffer.com/in-future-or-...              23   \n",
       "7       44  https://insights.blackcoffer.com/how-neural-ne...               3   \n",
       "8       45  https://insights.blackcoffer.com/how-machine-l...              34   \n",
       "9       46  https://insights.blackcoffer.com/deep-learning...              64   \n",
       "10      47  https://insights.blackcoffer.com/how-to-protec...              43   \n",
       "11      48  https://insights.blackcoffer.com/how-machines-...              32   \n",
       "12      49  https://insights.blackcoffer.com/ai-human-robo...              28   \n",
       "13      50  https://insights.blackcoffer.com/how-ai-will-c...              55   \n",
       "14      51  https://insights.blackcoffer.com/future-of-wor...              52   \n",
       "15      52  https://insights.blackcoffer.com/ai-tool-alexa...              26   \n",
       "16      53  https://insights.blackcoffer.com/ai-healthcare...              76   \n",
       "17      54  https://insights.blackcoffer.com/all-you-need-...              17   \n",
       "18      55  https://insights.blackcoffer.com/evolution-of-...              18   \n",
       "19      56  https://insights.blackcoffer.com/how-data-anal...               3   \n",
       "\n",
       "    NEGATIVE SCORE  POLARITY SCORE  SUBJECTIVITY SCORE  AVG SENTENCE LENGTH  \\\n",
       "0               30        0.325844            0.021855            37.490196   \n",
       "1               35        0.230770            0.020732            28.327273   \n",
       "2               34        0.326734            0.026830            29.031746   \n",
       "3               19        0.472223            0.030063            26.227273   \n",
       "4               21        0.353847            0.018823            36.640000   \n",
       "5               20        0.354840            0.023785            35.564103   \n",
       "6               11        0.352942            0.020135            22.846154   \n",
       "7                0        1.000001            0.022557           180.000000   \n",
       "8               13        0.446810            0.036146            29.724138   \n",
       "9               31        0.347369            0.021986            35.261538   \n",
       "10              49       -0.065216           -0.004443            23.376471   \n",
       "11              19        0.254903            0.014757            33.589744   \n",
       "12              21        0.142858            0.007496            25.660377   \n",
       "13              23        0.410257            0.028370            55.750000   \n",
       "14              19        0.464790            0.030001            33.877551   \n",
       "15               0        1.000001            0.057144            41.062500   \n",
       "16              39        0.321740            0.029696           327.666667   \n",
       "17               0        1.000001            0.028669            36.916667   \n",
       "18               5        0.565218            0.022338            44.684211   \n",
       "19               3        0.000001            0.000001           330.000000   \n",
       "\n",
       "    PERCENTAGE OF COMPLEX WORDS   FOG INDEX  AVG NUMBER OF WORDS PER SENTENCE  \\\n",
       "0                      0.361402   15.140639                         37.490196   \n",
       "1                      0.258023   11.434118                         28.327273   \n",
       "2                      0.344451   11.750479                         29.031746   \n",
       "3                      0.255921   10.593278                         26.227273   \n",
       "4                      0.280022   14.768009                         36.640000   \n",
       "5                      0.273252   14.334942                         35.564103   \n",
       "6                      0.286195    9.252940                         22.846154   \n",
       "7                      0.394444   72.157778                        180.000000   \n",
       "8                      0.266821   11.996384                         29.724138   \n",
       "9                      0.277051   14.215436                         35.261538   \n",
       "10                     0.285858    9.464931                         23.376471   \n",
       "11                     0.334351   13.569638                         33.589744   \n",
       "12                     0.291176   10.380622                         25.660377   \n",
       "13                     0.260090   22.404036                         55.750000   \n",
       "14                     0.296988   13.669816                         33.877551   \n",
       "15                     0.356164   16.567466                         41.062500   \n",
       "16                     0.251780  131.167379                        327.666667   \n",
       "17                     0.329571   14.898495                         36.916667   \n",
       "18                     0.347468   18.012671                         44.684211   \n",
       "19                     0.372727  132.149091                        330.000000   \n",
       "\n",
       "    COMPLEX WORD COUNT  WORD COUNT  SYLLABLE PER WORD  PERSONAL PRONOUNS  \\\n",
       "0                  691        1386                 14                  3   \n",
       "1                  402        1091                  8                  9   \n",
       "2                  630        1298                  9                  5   \n",
       "3                  443        1213                  8                 20   \n",
       "4                  513        1291                  9                 18   \n",
       "5                  379         985                  9                 23   \n",
       "6                  255         623                  9                  9   \n",
       "7                   71         137                  8                  2   \n",
       "8                  230         618                  8                  4   \n",
       "9                  635        1582                 10                 13   \n",
       "10                 568        1429                  9                  2   \n",
       "11                 438         930                  8                 11   \n",
       "12                 396         984                  8                  8   \n",
       "13                 464        1207                 10                 34   \n",
       "14                 493        1159                 12                 13   \n",
       "15                 234         470                  8                  2   \n",
       "16                 495        1338                  8                 18   \n",
       "17                 292         630                  9                  2   \n",
       "18                 295         604                 10                  3   \n",
       "19                 123         245                  8                  4   \n",
       "\n",
       "    AVG WORD LENGTH  \n",
       "0          7.135642  \n",
       "1          6.170486  \n",
       "2          6.901387  \n",
       "3          6.133553  \n",
       "4          6.503486  \n",
       "5          6.344162  \n",
       "6          6.608347  \n",
       "7          7.437956  \n",
       "8          6.223301  \n",
       "9          6.312263  \n",
       "10         6.524843  \n",
       "11         6.966667  \n",
       "12         6.389228  \n",
       "13         6.242751  \n",
       "14         6.644521  \n",
       "15         7.155319  \n",
       "16         5.915546  \n",
       "17         6.803175  \n",
       "18         7.226821  \n",
       "19         7.306122  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The output file is attached in the folder\n",
    "out_file=\"/Users/aryan/Documents/xcode/projects/Intern/blackcoffer/Output/Output Data Structure.xlsx\"\n",
    "df = pd.read_excel(out_file,sheet_name='Sheet1')\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61d1e4",
   "metadata": {},
   "source": [
    "#  This output file is attached in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7095e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
